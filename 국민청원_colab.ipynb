{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "국민청원_colab.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5OKsM-lvUW_",
        "colab_type": "text"
      },
      "source": [
        "## 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQyacn9HqgpN",
        "colab_type": "code",
        "outputId": "6c308656-241b-4ed1-8250-4c911a5383e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5P6pcQcvWwN",
        "colab_type": "text"
      },
      "source": [
        "## 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlQ4mzUtuy37",
        "colab_type": "code",
        "outputId": "f9819122-5fd9-45da-a22f-5a3ff54d7e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "! pip install konlpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.1)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P89c1dUuxtfy",
        "colab_type": "code",
        "outputId": "c357c786-b7b3-41d3-faae-e3245bc44135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pip install kss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kss in /usr/local/lib/python3.6/dist-packages (1.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbeLcT6u59u1",
        "colab_type": "code",
        "outputId": "043d7bad-775d-4588-a0fd-f8955b52b3f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqHzEQe8X3Sr",
        "colab_type": "code",
        "outputId": "917cd34c-3d87-4d24-ca1e-3c3d3d057345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "! pip install pytorch==0.1.2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch==0.1.2\n",
            "  Using cached https://files.pythonhosted.org/packages/a9/41/4487bc23e3ac4d674943176f5aa309427b011e00607eb98899e9d951f67b/pytorch-0.1.2.tar.gz\n",
            "Building wheels for collected packages: pytorch\n",
            "  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for pytorch\n",
            "Failed to build pytorch\n",
            "Installing collected packages: pytorch\n",
            "    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-41_2xjqu/pytorch/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-41_2xjqu/pytorch/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-jc30idq5/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKSZPIWcvaV9",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBnEY-YG6C_I",
        "colab_type": "code",
        "outputId": "a6d4baad-a3bf-46cb-da40-46574141c926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJEeSXZppWal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm_notebook\n",
        "from konlpy.tag import Okt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import kss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy_D7tBxpWay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/LAB/국민청원/petition_data_all_2019_01_09.csv'\n",
        "data = pd.read_csv(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCGX6ukypWa4",
        "colab_type": "code",
        "outputId": "172dbd64-3cca-41cb-f096-050d9de9438b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>category</th>\n",
              "      <th>start-days</th>\n",
              "      <th>end-days</th>\n",
              "      <th>person</th>\n",
              "      <th>progress</th>\n",
              "      <th>title</th>\n",
              "      <th>count</th>\n",
              "      <th>petition_overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>안전/환경</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>스텔라 데이지호에 대한 제안입니다.</td>\n",
              "      <td>9</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22</td>\n",
              "      <td>기타</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>비리제보처를 만들어주세요.</td>\n",
              "      <td>17</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현 정부에 국민들이 가장 원하는 것은 부...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>미래</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>제2의 개성공단</td>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t만일 하시는 대통령님 및 각 부처 장관님...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>일자리</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-08-26</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>공공기관 무조건적인 정규직전환을 반대합니다.</td>\n",
              "      <td>53</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현정부에서 정규직 일자리를 늘리는 것에 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>미래</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>제2의 개성공단</td>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t만일 하시는 대통령님 및 각 부처 장관님...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num category  ... count                                  petition_overview\n",
              "0   21    안전/환경  ...     9  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...\n",
              "1   22       기타  ...    17  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현 정부에 국민들이 가장 원하는 것은 부...\n",
              "2   23       미래  ...     0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t만일 하시는 대통령님 및 각 부처 장관님...\n",
              "3   24      일자리  ...    53  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현정부에서 정규직 일자리를 늘리는 것에 ...\n",
              "4   25       미래  ...     0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t만일 하시는 대통령님 및 각 부처 장관님...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Yf2YKk1ipWbD",
        "colab_type": "code",
        "outputId": "4316f899-0a51-4397-eeb1-43050422eb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(data.isnull().values.any())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbW1k-RepWbN",
        "colab_type": "code",
        "outputId": "df5e9416-f091-4316-bd46-f859f9001272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "371230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gPk681dpWbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop_duplicates(subset='petition_overview', keep='last')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_TyEKgspWbb",
        "colab_type": "code",
        "outputId": "a797a3f2-52e2-45f2-d9ce-027a1c701e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m85Di9apWbj",
        "colab_type": "code",
        "outputId": "b5343786-f643-4567-eac8-0d4d1f4c8d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "print(data.groupby('category').size().sort_values(ascending=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "category\n",
            "정치개혁           53258\n",
            "기타             43175\n",
            "인권/성평등         31114\n",
            "안전/환경          27542\n",
            "교통/건축/국토       25899\n",
            "외교/통일/국방       24462\n",
            "육아/교육          23557\n",
            "보건복지           22330\n",
            "일자리            20631\n",
            "행정             18145\n",
            "문화/예술/체육/언론    16571\n",
            "미래             16114\n",
            "경제민주화          15203\n",
            "성장동력            6469\n",
            "반려동물            3629\n",
            "저출산/고령화대책       3199\n",
            "농산어촌            1690\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4yp_JclpWbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_selected = ['정치개혁', '인권/성평등', '안전/환경', '교통/건축/국토', '외교/통일/국방']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7ESdq7pWb1",
        "colab_type": "code",
        "outputId": "172ed9c5-a1e7-4f17-f807-5b9a62b2884d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df = data[data['category'].isin(category_selected)]\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>category</th>\n",
              "      <th>start-days</th>\n",
              "      <th>end-days</th>\n",
              "      <th>person</th>\n",
              "      <th>progress</th>\n",
              "      <th>title</th>\n",
              "      <th>count</th>\n",
              "      <th>petition_overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>안전/환경</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>스텔라 데이지호에 대한 제안입니다.</td>\n",
              "      <td>9</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27</td>\n",
              "      <td>정치개혁</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-09-18</td>\n",
              "      <td>naver - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>김이수 헌재소장 임명 재고 건의</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문 대통령님께 묻습니다 (2017. 8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>33</td>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>naver - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>납득할 수 있는 장애 재판정을 받고 싶습니다.</td>\n",
              "      <td>15</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t안녕하십니까? 저는 경직형 양마비 뇌병변...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>35</td>\n",
              "      <td>외교/통일/국방</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-08-26</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>문재인정부는 신한국형 페리프로세스가 작성했습니다.</td>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님 신한국형 페리프로세스 로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>36</td>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-08-26</td>\n",
              "      <td>naver - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>한국채식인구 100만명. 학교 급식 및 군대에서 현미채식 선택권을 보장해주십시오!</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님과 각 정부 인사분들께 마...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    num  category  ... count                                  petition_overview\n",
              "0    21     안전/환경  ...     9  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...\n",
              "6    27      정치개혁  ...     1  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문 대통령님께 묻습니다 (2017. 8....\n",
              "12   33    인권/성평등  ...    15  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t안녕하십니까? 저는 경직형 양마비 뇌병변...\n",
              "14   35  외교/통일/국방  ...     0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님 신한국형 페리프로세스 로...\n",
              "15   36    인권/성평등  ...     1  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님과 각 정부 인사분들께 마...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4mqYZJFpWb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df['petition_overview']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7-iKoxcpWcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g0khwexpWcH",
        "colab_type": "code",
        "outputId": "c8d3ef6e-5507-4e3c-dd3e-009c1f35e292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "X[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...\n",
              "6     \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문 대통령님께 묻습니다 (2017. 8....\n",
              "12    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t안녕하십니까? 저는 경직형 양마비 뇌병변...\n",
              "14    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님 신한국형 페리프로세스 로...\n",
              "15    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님과 각 정부 인사분들께 마...\n",
              "17    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님 한중관계 사드 갈등 해소...\n",
              "19    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t지금부터 67년전 1950년 6.25전쟁...\n",
              "25    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t지금부터 67년전 1950년 6.25전쟁...\n",
              "30    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t간절히 간절히 간청 드립니다. \\n\\n\\...\n",
              "54    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t※지장물관련 국토부의 해석 : 기존 건축...\n",
              "Name: petition_overview, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwydAmFCpWcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRHXGF47pWcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpoGwXuHpWcb",
        "colab_type": "code",
        "outputId": "ecdfdbb6-81cf-4836-eb32-40ef44685ec9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "129820\n",
            "32455\n",
            "129820\n",
            "32455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGdx9tJSpWcj",
        "colab_type": "code",
        "outputId": "58be44f5-c950-467c-af05-0f79c6a76572",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "print(X_train.head())\n",
        "print(y_train.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "333598    봄에 이어 이번 가을 겨울에도 어김없이 미세먼지가 왔습니다 적어도 봄에는 마스크 안...\n",
            "344228    부동산 계약 전산화 해야 합니다  부동산 계약 전산화 해야 합니다  부동산 계약 전...\n",
            "300621    어제 뉴스를 보고 너무 어이가 없어서 올려봅니다 동료들한테 처음 들었을 때 너무 황...\n",
            "285042    최근 국방의 의무에 관련하여 지속적으로 이야기가 나오고있습니다 국방의 의무에대하여 ...\n",
            "26544                                          조두순 재심 해주세요 \n",
            "Name: petition_overview, dtype: object\n",
            "333598       안전/환경\n",
            "344228    교통/건축/국토\n",
            "300621      인권/성평등\n",
            "285042    외교/통일/국방\n",
            "26544        안전/환경\n",
            "Name: category, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKHTsr9F0lSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_add(body):\n",
        "    lst = kss.split_sentences(body)\n",
        "    result = [\"[SEP]\"] * (len(lst) * 2 + 1)\n",
        "    result[1::2] = lst\n",
        "    result[0] = \"[CLS]\"\n",
        "    sentence = ' '.join(result)\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX11cyCn65rQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {'정치개혁': 0, '인권/성평등': 1, '안전/환경': 2, '교통/건축/국토': 3, '외교/통일/국방': 4}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La_E96eVyH2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_bert = []\n",
        "for body in X_train:\n",
        "    X_train_bert.append(bert_add(body))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPkZNltZ5sQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_bert = []\n",
        "for label in y_train:\n",
        "    y_train_bert.append(label_dict[label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxc-PCeF7Ch5",
        "colab_type": "code",
        "outputId": "a7073680-48a6-4f47-94ec-344f75984ab8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in X_train_bert]\n",
        "\n",
        "print (X_train_bert[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 봄에 이어 이번 가을 겨울에도 어김없이 미세먼지가 왔습니다 [SEP] 적어도 봄에는 마스크 안써도 이정도까지는 아니였습니다 [SEP] 근데 지금 하늘이 뿌얗다못해 누렇습니다 [SEP] 게다가 마스크를 쓰는데도 불구하고 실내에 공기청정기를 켰는데도 불구하고 목이 계속 칼칼합니다 [SEP] 다음날 아침에는 목에 자꾸 가래가 생깁니다 [SEP] 미세먼지임에도 불구하고 누구는 목이 아픈게 환절기때문에 감기에 걸린것 같다고 합니다 [SEP] 또 밖이 뿌얗다보니 안개라고 오해하는 사람도 있었습니다 [SEP] 봄에는 미세먼지를 중국이 아닌 자동차 매연때문이라며 자가용 이용을 자제하고 대중교통을 이용하라고 교통비를 안받던적도 있었습니다 [SEP] 국민이 바보입니까 자동차 매연때문인지 중국에서 날라오는건지도 모를만큼요 지금 북한에 신경쓰고 계신건 알고 있습니다만 국민 먼저 살리는게 우선아닐까요 [SEP] 우리나라의 앞으로의 미래  먼 미래를 위해 앞으로 이나라에서 커갈 아이들을 위해 안전을 위해 그러시는건 알고있습니다 [SEP] 하지만 그 미래를 맞이하기도 전에 미세먼지 때문에 아플 아이들이 국민들이 있을 수 있습니다 [SEP] 건강해야 살아야 뭐든 좋게 맞이하지 않을까요 [SEP] 지금의 문제도 뒤돌아 봐주시길 바랍니다 [SEP] 미세먼지 해결 부탁드립니다 [SEP]\n",
            "['[CLS]', '봄', '##에', '이어', '이', '##번', '가', '##을', '겨', '##울', '##에도', '어', '##김', '##없', '##이', '미', '##세', '##먼', '##지가', '왔', '##습', '##니다', '[SEP]', '적', '##어', '##도', '봄', '##에는', '마', '##스', '##크', '안', '##써', '##도', '이', '##정', '##도', '##까지', '##는', '아', '##니', '##였', '##습', '##니다', '[SEP]', '근', '##데', '지', '##금', '하', '##늘', '##이', '[UNK]', '누', '##렇', '##습', '##니다', '[SEP]', '게', '##다가', '마', '##스', '##크', '##를', '쓰', '##는데', '##도', '불구하고', '실', '##내', '##에', '공', '##기', '##청', '##정', '##기를', '켰', '##는데', '##도', '불구하고', '목', '##이', '계속', '칼', '##칼', '##합', '##니다', '[SEP]', '다음', '##날', '아', '##침', '##에는', '목', '##에', '자', '##꾸', '가', '##래', '##가', '생', '##깁', '##니다', '[SEP]', '미', '##세', '##먼', '##지', '##임', '##에도', '불구하고', '누', '##구', '##는', '목', '##이', '아', '##픈', '##게', '환', '##절', '##기', '##때', '##문', '##에', '감', '##기에', '걸', '##린', '##것', '같다', '##고', '합', '##니다', '[SEP]', '또', '밖', '##이', '[UNK]', '안', '##개', '##라고', '오', '##해', '##하는', '사', '##람', '##도', '있', '##었', '##습', '##니다', '[SEP]', '봄', '##에는', '미', '##세', '##먼', '##지를', '중국', '##이', '아닌', '자', '##동차', '매', '##연', '##때', '##문', '##이', '##라', '##며', '자', '##가', '##용', '이', '##용을', '자', '##제', '##하고', '대', '##중', '##교', '##통', '##을', '이', '##용', '##하라', '##고', '교', '##통', '##비', '##를', '안', '##받', '##던', '##적', '##도', '있', '##었', '##습', '##니다', '[SEP]', '국', '##민', '##이', '바', '##보', '##입', '##니', '##까', '자', '##동차', '매', '##연', '##때', '##문', '##인', '##지', '중국', '##에서', '날', '##라', '##오는', '##건', '##지', '##도', '모', '##를', '##만', '##큼', '##요', '지', '##금', '북', '##한', '##에', '신', '##경', '##쓰', '##고', '계', '##신', '##건', '알', '##고', '있', '##습', '##니다', '##만', '국', '##민', '먼저', '살', '##리는', '##게', '우', '##선', '##아', '##닐', '##까', '##요', '[SEP]', '우', '##리', '##나라', '##의', '앞', '##으로', '##의', '미', '##래', '먼', '미', '##래', '##를', '위해', '앞', '##으로', '이', '##나라', '##에서', '커', '##갈', '아', '##이', '##들을', '위해', '안', '##전을', '위해', '그', '##러', '##시', '##는', '##건', '알', '##고', '##있', '##습', '##니다', '[SEP]', '하지만', '그', '미', '##래', '##를', '맞', '##이', '##하기도', '전에', '미', '##세', '##먼', '##지', '때문에', '아', '##플', '아', '##이', '##들이', '국', '##민', '##들이', '있을', '수', '있', '##습', '##니다', '[SEP]', '건', '##강', '##해야', '살', '##아', '##야', '뭐', '##든', '좋', '##게', '맞', '##이', '##하지', '않', '##을', '##까', '##요', '[SEP]', '지', '##금', '##의', '문', '##제', '##도', '뒤', '##돌', '##아', '봐', '##주시', '##길', '바', '##랍', '##니다', '[SEP]', '미', '##세', '##먼', '##지', '해', '##결', '부', '##탁', '##드', '##립', '##니다', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_hABlHe86fI",
        "colab_type": "code",
        "outputId": "ecdce549-37d1-41f1-db95-6ad90903d8b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "MAX_LEN = 256\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9360,  10530,  64749,   9638,  35465,   8843,  10622,\n",
              "         8877,  78123,  35979,   9546, 118667, 119136,  10739,   9309,\n",
              "        24982, 118922,  80795,   9594, 119081,  48345,    102,   9664,\n",
              "        12965,  12092,   9360,  15303,   9246,  12605,  20308,   9521,\n",
              "        73131,  12092,   9638,  16605,  12092,  18382,  11018,   9519,\n",
              "        25503, 119147, 119081,  48345,    102,   8926,  28911,   9706,\n",
              "        40032,   9952, 118762,  10739,    100,   9032, 118871, 119081,\n",
              "        48345,    102,   8872,  80244,   9246,  12605,  20308,  11513,\n",
              "         9511,  41850,  12092, 103279,   9489,  31605,  10530,   8896,\n",
              "        12310,  40311,  16605,  29669,   9811,  41850,  12092, 103279,\n",
              "         9284,  10739,  77039,   9788, 119287,  33188,  48345,    102,\n",
              "        52292,  41919,   9519, 119285,  15303,   9284,  10530,   9651,\n",
              "       118694,   8843,  37388,  11287,   9420, 118668,  48345,    102,\n",
              "         9309,  24982, 118922,  12508,  36240,  35979, 103279,   9032,\n",
              "        17196,  11018,   9284,  10739,   9519, 119411,  14153,   9995,\n",
              "        58931,  12310, 118832,  25934,  10530,   8848,  33797,   8867,\n",
              "        27654, 118627,  53354,  11664,   9957,  48345,    102,   9144,\n",
              "         9320,  10739,    100,   9521,  21789,  59894,   9580,  14523,\n",
              "        12178,   9405,  61250,  12092,   9647, 119138, 119081,  48345,\n",
              "          102,   9360,  15303,   9309,  24982, 118922,  36908,  45397,\n",
              "        10739,  63783,   9651,  99183,   9258,  25486, 118832,  25934,\n",
              "        10739,  17342,  21406,   9651,  11287,  24974,   9638,  72444,\n",
              "         9651,  17730,  12453,   9069,  41693,  25242,  43022,  10622,\n",
              "         9638,  24974, 101656,  11664,   8907,  43022,  29455,  11513,\n",
              "         9521, 118965,  23990,  14801,  12092,   9647, 119138, 119081,\n",
              "        48345,    102,   8909,  36553,  10739,   9318,  30005,  58303,\n",
              "        25503, 118671,   9651,  99183,   9258,  25486, 118832,  25934,\n",
              "        12030,  12508,  45397,  11489,   8985,  17342,  82823,  71439,\n",
              "        12508,  12092,   9283,  11513,  19105, 119328,  48549,   9706,\n",
              "        40032,   9366,  11102,  10530,   9487,  31720, 119103,  11664,\n",
              "         8887,  25387,  71439,   9524,  11664,   9647, 119081,  48345,\n",
              "        19105,   8909,  36553, 104304,   9408,  26344,  14153,   9604])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx0D-TT19DOT",
        "colab_type": "code",
        "outputId": "278a255f-2933-4682-ff3e-9396abcbafa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckB-H0dw9Luj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    y_train_bert, \n",
        "                                                                                    random_state=2018, \n",
        "                                                                                    test_size=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Fo6R7o9RIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=2018, \n",
        "                                                       test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lyfQsYn9VS7",
        "colab_type": "code",
        "outputId": "6ff4807a-37a2-4d9e-8797-e4ccfdb700ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,   9665,  24982,  13764,  40032,  14423,  52363,  10892,   8924,\n",
            "         21711,  89523,  11261,   9489,  12424,  36553,  10622,  28195,   9670,\n",
            "        119254,  58303,  48345,    102,   9978,   9665,  24982,  13764,  40032,\n",
            "          9069,  52363,  10892,   9689, 119342,  13764,   8939,  28578,   9322,\n",
            "         10622,   9460,  13767, 118624,  11261,   9524,  11664,   9647, 119081,\n",
            "         48345,    102,   9689, 119342,  38939,   9881,  29669,   9960, 118991,\n",
            "         13764,    100,   9551,  23811,  16439,   9955, 118671,  48549,    102,\n",
            "          9638,   9670, 119254,  10892,   8924,  21711,  89523,  11261,   9448,\n",
            "        118813,  40364,   8928,  15891,  48387,  19105,  79633,   9670, 119254,\n",
            "         58303,  48345,    102,   9665,   9102,   9519,  87456,   9553,  23811,\n",
            "         11261,   9663,  49515,   9711,  10892,   9256,  68773,  10739,  11261,\n",
            "          9131,   9568, 118989,   9645,  48345,    102, 103596,   9465,  13764,\n",
            "         19105,   9356,  14867,   9835,   9089,  10739,  59894,   9420,  66540,\n",
            "         35506, 118632,  28578,  10019,  15891,  48387,  10530, 118629,   8924,\n",
            "        118871,  12508,   9523, 119081,  48345,    102,   9604,  12692,  82490,\n",
            "         92383,   9022,  31531,   9069, 119254,   9365,  52560,  11102,   8982,\n",
            "         17342,  11489,  10019,  15891,  48387,  92413,   9089,  10622,   9338,\n",
            "         82034,  71439,   9663,   9987,  13764,   9056, 119103,  11018,  14153,\n",
            "          9519,  25503, 119217,   9543,  11287,   9365,  39420, 108578,   9638,\n",
            "          9008,  10892,   8982,  10739,  10530,   9613,  24982,  10530,   9405,\n",
            "         14040,  41850,   8924,   9367,  27023,   9420, 119446,  29455,  12092,\n",
            "          9743,  89045,  15001,  26737,  21711,  35506, 119217,   9519,  10739,\n",
            "         27023,   9543,  83811,  29455,  10530,   8907,  83811,  29455,   9405,\n",
            "         31503,   9568, 118989,  29805,   9532,   9105,   9838,  27355,  30936,\n",
            "         48253,  10530,   9711,   9408,   9460, 119192, 119081,  25503, 118671,\n",
            "          9435,  31531,  11261,   9613,  37568,  10459,   9321,  10622,   9663,\n",
            "         40032,  14102,  14523,  12092,   9018,  10530,   9087,   9290,   9283,\n",
            "         16985,  48549,    102,   9018,  10622,   9460,  58303,  10459,   9321,\n",
            "         10622,   9663,  70122,  14523])\n",
            "tensor(3)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])\n",
            "tensor([   101,   8935,  30005,  49543,  78930,  19105,  10459,   9654, 118940,\n",
            "         10739,   9519, 108578,  35979, 103279,   9004,  32537,  25685,  97802,\n",
            "          9491,  11102,  89523,  11261,   9414,  60469,  11513,   9696, 119081,\n",
            "         48345,    102,   9708, 119235,   9297,  87164,   8935,  30005,  49543,\n",
            "         18471,  73894,  63783,   9385,  14871,  25486, 109265,  58303,  48345,\n",
            "           102,   9954,  35465,  10459,   9489,  91921,   8909,  14423,   9319,\n",
            "        119336,  10892,   9004,  32537,   9491,  33188,  48345,    102,   8935,\n",
            "         30005,  49543,  18471,  73894,   9638,  35465,   8932,  14863,  11261,\n",
            "          9321,  17138,  12453,   9344,  10739, 119233,  11489,   9074,  79633,\n",
            "          9283, 119081,   9356,  29935,  16323,  14867,   9685, 118632, 119081,\n",
            "         48345,    102,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjR-vcpd9XHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwN-NYm86wWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_bert = []\n",
        "for body in X_test:\n",
        "    X_test_bert.append(bert_add(body))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fSjR8om62ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_bert = []\n",
        "for label in y_test:\n",
        "    y_test_bert.append(label_dict[label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8IfD7Ze9hDu",
        "colab_type": "code",
        "outputId": "9587475c-828a-4c76-ddf8-597a82979e72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in X_test_bert]\n",
        "\n",
        "print (X_test_bert[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 주정차 위반한 차량을 구청소속 견인사무소에서 견인해갈때  왜 사전에 연락이 아예 없이 그대로 견인을 해가는지 저의가 궁금합니다 [SEP] 견인사무소에 가서 따져물어도 관련 근거 조례나 법령도 대지못하니 과태료및 견인비용을 수령하시는 분들은 욕한마디 먹지않고 수령하기는 거의 불가능하구요 [SEP] 연락을 하고 분정도뒤에 견인해가면  그나마 그분들이 욕도 안먹고 납부자들도 인정할수밖에없다고 생각합니다 [SEP] 아니면 정책을 만드시는 분들은 세금을 걷어야하고  세금을 수령하는 과정에서 수령기관자들이 욕먹는 것은 자신이 욕먹는게 아니니까 상관없다는 식으로 일임 하시는건가요 [SEP] 저의가 상당히 궁금합니다 [SEP] 왜 연락이나 통보 한마디 없이 견인해가는 속내가 뭡니까 [SEP]\n",
            "['[CLS]', '주', '##정', '##차', '위', '##반', '##한', '차', '##량', '##을', '구', '##청', '##소', '##속', '견', '##인', '##사', '##무', '##소', '##에서', '견', '##인', '##해', '##갈', '##때', '왜', '사', '##전에', '연', '##락', '##이', '아', '##예', '없이', '그대로', '견', '##인을', '해', '##가는', '##지', '저', '##의', '##가', '궁', '##금', '##합', '##니다', '[SEP]', '견', '##인', '##사', '##무', '##소', '##에', '가', '##서', '따', '##져', '##물', '##어', '##도', '관련', '근', '##거', '조', '##례', '##나', '법', '##령', '##도', '대', '##지', '##못', '##하', '##니', '과', '##태', '##료', '##및', '견', '##인', '##비', '##용을', '수', '##령', '##하', '##시', '##는', '분', '##들은', '욕', '##한', '##마', '##디', '먹', '##지', '##않', '##고', '수', '##령', '##하기', '##는', '거의', '불', '##가', '##능', '##하', '##구', '##요', '[SEP]', '연', '##락', '##을', '하고', '분', '##정', '##도', '##뒤', '##에', '견', '##인', '##해', '##가', '##면', '그', '##나', '##마', '그', '##분', '##들이', '욕', '##도', '안', '##먹', '##고', '납', '##부', '##자', '##들', '##도', '인', '##정', '##할', '##수', '##밖', '##에', '##없', '##다고', '생', '##각', '##합', '##니다', '[SEP]', '아', '##니', '##면', '정', '##책', '##을', '만', '##드', '##시', '##는', '분', '##들은', '세', '##금', '##을', '걷', '##어', '##야', '##하고', '세', '##금', '##을', '수', '##령', '##하는', '과', '##정에서', '수', '##령', '##기', '##관', '##자', '##들이', '욕', '##먹', '##는', '것은', '자신이', '욕', '##먹', '##는', '##게', '아', '##니', '##니', '##까', '상', '##관', '##없', '##다는', '식', '##으로', '일', '##임', '하', '##시', '##는', '##건', '##가', '##요', '[SEP]', '저', '##의', '##가', '상', '##당', '##히', '궁', '##금', '##합', '##니다', '[SEP]', '왜', '연', '##락', '##이나', '통', '##보', '한', '##마', '##디', '없이', '견', '##인', '##해', '##가는', '속', '##내', '##가', '[UNK]', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hQoL5n090zo",
        "colab_type": "code",
        "outputId": "a34f1b55-fa6c-4c5e-f679-59ce1bffcea3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        }
      },
      "source": [
        "MAX_LEN = 256\n",
        "\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9689,  16605,  23466,   9619,  30134,  11102,   9730,\n",
              "        44321,  10622,   8908,  40311,  22333,  43962,   8880,  12030,\n",
              "        12945,  32537,  22333,  11489,   8880,  12030,  14523, 101202,\n",
              "       118832,   9596,   9405,  68767,   9568, 107693,  10739,   9519,\n",
              "        96279,  73610, 110589,   8880,  83200,   9960,  68828,  12508,\n",
              "         9663,  10459,  11287,   8916,  40032,  33188,  48345,    102,\n",
              "         8880,  12030,  12945,  32537,  22333,  10530,   8843,  12424,\n",
              "         9130,  41584,  29364,  12965,  12092,  86080,   8926,  41521,\n",
              "         9678,  58762,  16439,   9341,  44220,  12092,   9069,  12508,\n",
              "       118940,  35506,  25503,   8898,  83616,  38688, 118961,   8880,\n",
              "        12030,  29455,  72444,   9460,  44220,  35506,  14040,  11018,\n",
              "         9367,  22879,   9600,  11102,  23811,  48446,   9266,  12508,\n",
              "       119112,  11664,   9460,  44220,  22440,  11018,  55067,   9368,\n",
              "        11287,  74986,  35506,  17196,  48549,    102,   9568, 107693,\n",
              "        10622,  32487,   9367,  16605,  12092, 118809,  10530,   8880,\n",
              "        12030,  14523,  11287,  14867,   8924,  16439,  23811,   8924,\n",
              "        37712,  20173,   9600,  12092,   9521, 118921,  11664,   8988,\n",
              "        14646,  13764,  27023,  12092,   9640,  16605,  14843,  15891,\n",
              "       118964,  10530, 119136,  85634,   9420,  66540,  33188,  48345,\n",
              "          102,   9519,  25503,  14867,   9670, 119254,  10622,   9248,\n",
              "        15001,  14040,  11018,   9367,  22879,   9435,  40032,  10622,\n",
              "         8866,  12965,  21711,  12453,   9435,  40032,  10622,   9460,\n",
              "        44220,  12178,   8898,  87437,   9460,  44220,  12310,  20595,\n",
              "        13764,  20173,   9600, 118921,  11018,  30050,  79370,   9600,\n",
              "       118921,  11018,  14153,   9519,  25503,  25503, 118671,   9414,\n",
              "        20595, 119136,  82034,   9486,  11467,   9641,  36240,   9952,\n",
              "        14040,  11018,  71439,  11287,  48549,    102,   9663,  10459,\n",
              "        11287,   9414,  21928,  18108,   8916,  40032,  33188,  48345,\n",
              "          102,   9596,   9568, 107693,  43739,   9879,  30005,   9954,\n",
              "        23811,  48446,  73610,   8880,  12030,  14523,  68828,   9449,\n",
              "        31605,  11287,    100,    102,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmwhcQQR95JN",
        "colab_type": "code",
        "outputId": "e4126196-e54c-4d6e-d71c-781f6c4da5e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcttgfyQ96hp",
        "colab_type": "code",
        "outputId": "1d2bd015-3061-4e0a-af95-de934db37c10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "source": [
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(y_test_bert)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([   101,   9689,  16605,  23466,   9619,  30134,  11102,   9730,  44321,\n",
            "         10622,   8908,  40311,  22333,  43962,   8880,  12030,  12945,  32537,\n",
            "         22333,  11489,   8880,  12030,  14523, 101202, 118832,   9596,   9405,\n",
            "         68767,   9568, 107693,  10739,   9519,  96279,  73610, 110589,   8880,\n",
            "         83200,   9960,  68828,  12508,   9663,  10459,  11287,   8916,  40032,\n",
            "         33188,  48345,    102,   8880,  12030,  12945,  32537,  22333,  10530,\n",
            "          8843,  12424,   9130,  41584,  29364,  12965,  12092,  86080,   8926,\n",
            "         41521,   9678,  58762,  16439,   9341,  44220,  12092,   9069,  12508,\n",
            "        118940,  35506,  25503,   8898,  83616,  38688, 118961,   8880,  12030,\n",
            "         29455,  72444,   9460,  44220,  35506,  14040,  11018,   9367,  22879,\n",
            "          9600,  11102,  23811,  48446,   9266,  12508, 119112,  11664,   9460,\n",
            "         44220,  22440,  11018,  55067,   9368,  11287,  74986,  35506,  17196,\n",
            "         48549,    102,   9568, 107693,  10622,  32487,   9367,  16605,  12092,\n",
            "        118809,  10530,   8880,  12030,  14523,  11287,  14867,   8924,  16439,\n",
            "         23811,   8924,  37712,  20173,   9600,  12092,   9521, 118921,  11664,\n",
            "          8988,  14646,  13764,  27023,  12092,   9640,  16605,  14843,  15891,\n",
            "        118964,  10530, 119136,  85634,   9420,  66540,  33188,  48345,    102,\n",
            "          9519,  25503,  14867,   9670, 119254,  10622,   9248,  15001,  14040,\n",
            "         11018,   9367,  22879,   9435,  40032,  10622,   8866,  12965,  21711,\n",
            "         12453,   9435,  40032,  10622,   9460,  44220,  12178,   8898,  87437,\n",
            "          9460,  44220,  12310,  20595,  13764,  20173,   9600, 118921,  11018,\n",
            "         30050,  79370,   9600, 118921,  11018,  14153,   9519,  25503,  25503,\n",
            "        118671,   9414,  20595, 119136,  82034,   9486,  11467,   9641,  36240,\n",
            "          9952,  14040,  11018,  71439,  11287,  48549,    102,   9663,  10459,\n",
            "         11287,   9414,  21928,  18108,   8916,  40032,  33188,  48345,    102,\n",
            "          9596,   9568, 107693,  43739,   9879,  30005,   9954,  23811,  48446,\n",
            "         73610,   8880,  12030,  14523,  68828,   9449,  31605,  11287,    100,\n",
            "           102,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0])\n",
            "tensor(3)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Wn4iSY-EkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxdURrvA-G0L",
        "colab_type": "code",
        "outputId": "655b0f67-618e-45e3-deb4-6e39b73ed52f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5mElZBb-I70",
        "colab_type": "code",
        "outputId": "60ab34c7-63f2-452c-cf79-ed41942354a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJztaLr2-KRW",
        "colab_type": "code",
        "outputId": "f95a73a6-05c0-4b8f-9b62-4ce08f674717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onhakyaA-Ly9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0hSAjgN-Qqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhC_YdK-R6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m70Hyqvp-S9E",
        "colab_type": "code",
        "outputId": "52a836dc-eb4f-4772-8821-499382d856e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-d4cc234bbef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# 총 로스 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Backward 수행으로 그래디언트 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BtHiaum-Ui9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waQQePpm_JUs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}