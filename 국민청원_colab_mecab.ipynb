{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "국민청원_colab_mecab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36a247b84adf4e958a6d55302a960f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e4545e5b6dda4516ae0e3fd1115526a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_99ac7cd00eeb40c0ac6b22c0eb0759bf",
              "IPY_MODEL_76341434a51a4f8eab9969d18b421140"
            ]
          }
        },
        "e4545e5b6dda4516ae0e3fd1115526a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99ac7cd00eeb40c0ac6b22c0eb0759bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f5496314dc04115aa63267e2a18d0c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 129820,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 129820,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bbf24a37a3a4487826e62659bdad18a"
          }
        },
        "76341434a51a4f8eab9969d18b421140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_02109d98293d48ad9f54e5f7c1b9238b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 129820/129820 [02:36&lt;00:00, 831.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3da0556a16445c2a346981d9542c438"
          }
        },
        "1f5496314dc04115aa63267e2a18d0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bbf24a37a3a4487826e62659bdad18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "02109d98293d48ad9f54e5f7c1b9238b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3da0556a16445c2a346981d9542c438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c6b7cc3ca82e47b688628a77bcab8ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_99b07a1086c24bf8a4ab2dc9918cdec7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac77aaed79794544b2788a0dad5ff710",
              "IPY_MODEL_32d80a28400d4beba36dd42942d0600d"
            ]
          }
        },
        "99b07a1086c24bf8a4ab2dc9918cdec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac77aaed79794544b2788a0dad5ff710": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e7eb3b42704842988479885ad3c9766d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 32455,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 32455,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6586c3f4ecf047aea61c946c2b4ce468"
          }
        },
        "32d80a28400d4beba36dd42942d0600d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2f74e475ac15479994bb9c1315181268",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 32455/32455 [00:38&lt;00:00, 836.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02923463410c4a6eb21ae42dffae7df1"
          }
        },
        "e7eb3b42704842988479885ad3c9766d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6586c3f4ecf047aea61c946c2b4ce468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f74e475ac15479994bb9c1315181268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02923463410c4a6eb21ae42dffae7df1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "761e88f83d704ed59ce068eeb81ea978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_89cb51f21d204630b8045a1efa5b0237",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10640f19e1e940e6b3a780b9ba8af291",
              "IPY_MODEL_9dfe51ed93c14c9a92d7b88cc473223b"
            ]
          }
        },
        "89cb51f21d204630b8045a1efa5b0237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10640f19e1e940e6b3a780b9ba8af291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a99cdcd63fbf42b2b43599763b866078",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bc345573f8b546ff8a6b0e9e15c4259f"
          }
        },
        "9dfe51ed93c14c9a92d7b88cc473223b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc984c98797a49b1b729788551371934",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 714M/714M [00:09&lt;00:00, 72.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c92eae3851944858df66ecac26754c6"
          }
        },
        "a99cdcd63fbf42b2b43599763b866078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bc345573f8b546ff8a6b0e9e15c4259f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc984c98797a49b1b729788551371934": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c92eae3851944858df66ecac26754c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5OKsM-lvUW_",
        "colab_type": "text"
      },
      "source": [
        "## 드라이브 마운트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQyacn9HqgpN",
        "colab_type": "code",
        "outputId": "46f47d47-28a3-4c0a-d60f-7410eb7db14e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5P6pcQcvWwN",
        "colab_type": "text"
      },
      "source": [
        "## 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlQ4mzUtuy37",
        "colab_type": "code",
        "outputId": "a7dde314-0a09-4ddc-f370-2754de708500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "! pip install konlpy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P89c1dUuxtfy",
        "colab_type": "code",
        "outputId": "3418b9b7-d086-4637-c589-a1394416ab46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pip install kss"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kss in /usr/local/lib/python3.6/dist-packages (1.2.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbeLcT6u59u1",
        "colab_type": "code",
        "outputId": "4adecfca-c3af-4117-bba6-a9add469038c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.9)\n",
            "Requirement already satisfied: tokenizers==0.0.11 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers) (2.6.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GTgccqCNHD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "716e514b-2313-4624-8c7e-bdd504d35b00"
      },
      "source": [
        "! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJcRy4v-NO2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c657c7eb-1a79-4a57-da7e-cb03ca48b79b"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqtdjBTLNRO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d5e84fd3-68d6-4330-9e3e-dec843898efd"
      },
      "source": [
        "! bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.17.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2020-02-05 11:38:04--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.1, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=RkZyhCV5cpBLdHeCmrOmYQ7Z3Ok%3D&Expires=1580904003&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22 [following]\n",
            "--2020-02-05 11:38:04--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=RkZyhCV5cpBLdHeCmrOmYQ7Z3Ok%3D&Expires=1580904003&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.109.67\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.109.67|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.1’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  7.73MB/s    in 0.2s    \n",
            "\n",
            "2020-02-05 11:38:04 (7.73 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.1’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2020-02-05 11:38:19--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.1, 18.205.93.0, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=ZQ3jUFXPNpGnQjbqO3SGDQjTA70%3D&Expires=1580904086&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22 [following]\n",
            "--2020-02-05 11:38:19--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=ZQ3jUFXPNpGnQjbqO3SGDQjTA70%3D&Expires=1580904086&AWSAccessKeyId=AKIAIQWXW6WLXMB5QZAQ&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.233.227\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.233.227|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  57.8MB/s    in 0.8s    \n",
            "\n",
            "2020-02-05 11:38:20 (57.8 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKSZPIWcvaV9",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBnEY-YG6C_I",
        "colab_type": "code",
        "outputId": "7962a790-fb36-455b-e6ed-35e74d2904f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJEeSXZppWal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm_notebook\n",
        "from konlpy.tag import Mecab\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import kss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy_D7tBxpWay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = '/content/drive/My Drive/Colab Notebooks/LAB/국민청원/petition_data_all_2019_01_09.csv'\n",
        "data = pd.read_csv(data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCGX6ukypWa4",
        "colab_type": "code",
        "outputId": "45a6d20d-ba23-45a8-b1e6-4f14baaa591d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>category</th>\n",
              "      <th>start-days</th>\n",
              "      <th>end-days</th>\n",
              "      <th>person</th>\n",
              "      <th>progress</th>\n",
              "      <th>title</th>\n",
              "      <th>count</th>\n",
              "      <th>petition_overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>안전/환경</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>스텔라 데이지호에 대한 제안입니다.</td>\n",
              "      <td>9</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22</td>\n",
              "      <td>기타</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>비리제보처를 만들어주세요.</td>\n",
              "      <td>17</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현 정부에 국민들이 가장 원하는 것은 부...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23</td>\n",
              "      <td>미래</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>제2의 개성공단</td>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t만일 하시는 대통령님 및 각 부처 장관님...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>일자리</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-08-26</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>공공기관 무조건적인 정규직전환을 반대합니다.</td>\n",
              "      <td>53</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현정부에서 정규직 일자리를 늘리는 것에 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25</td>\n",
              "      <td>미래</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-09-03</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>제2의 개성공단</td>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t만일 하시는 대통령님 및 각 부처 장관님...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num category  ... count                                  petition_overview\n",
              "0   21    안전/환경  ...     9  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...\n",
              "1   22       기타  ...    17  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현 정부에 국민들이 가장 원하는 것은 부...\n",
              "2   23       미래  ...     0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t만일 하시는 대통령님 및 각 부처 장관님...\n",
              "3   24      일자리  ...    53  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t현정부에서 정규직 일자리를 늘리는 것에 ...\n",
              "4   25       미래  ...     0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t만일 하시는 대통령님 및 각 부처 장관님...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KqeNpvBknKY",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Yf2YKk1ipWbD",
        "colab_type": "code",
        "outputId": "d6cfe5f5-cc3f-4b04-bf8b-ad1ec2430886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(data.isnull().values.any())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbW1k-RepWbN",
        "colab_type": "code",
        "outputId": "bb51371e-ba7b-4069-a0e6-b6277ca14a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "371230"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gPk681dpWbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop_duplicates(subset='petition_overview', keep='last')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_TyEKgspWbb",
        "colab_type": "code",
        "outputId": "2dd9f324-81f3-43b8-e12c-0a2222deb017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352988"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m85Di9apWbj",
        "colab_type": "code",
        "outputId": "1876c1db-dbb3-4b37-fdfa-4dd29347c9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "print(data.groupby('category').size().sort_values(ascending=False))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "category\n",
            "정치개혁           53258\n",
            "기타             43175\n",
            "인권/성평등         31114\n",
            "안전/환경          27542\n",
            "교통/건축/국토       25899\n",
            "외교/통일/국방       24462\n",
            "육아/교육          23557\n",
            "보건복지           22330\n",
            "일자리            20631\n",
            "행정             18145\n",
            "문화/예술/체육/언론    16571\n",
            "미래             16114\n",
            "경제민주화          15203\n",
            "성장동력            6469\n",
            "반려동물            3629\n",
            "저출산/고령화대책       3199\n",
            "농산어촌            1690\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4yp_JclpWbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_selected = ['정치개혁', '인권/성평등', '안전/환경', '교통/건축/국토', '외교/통일/국방']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD7ESdq7pWb1",
        "colab_type": "code",
        "outputId": "498f49ab-98d9-4baf-c828-8eb927e2d380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "df = data[data['category'].isin(category_selected)]\n",
        "df.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>category</th>\n",
              "      <th>start-days</th>\n",
              "      <th>end-days</th>\n",
              "      <th>person</th>\n",
              "      <th>progress</th>\n",
              "      <th>title</th>\n",
              "      <th>count</th>\n",
              "      <th>petition_overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21</td>\n",
              "      <td>안전/환경</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>스텔라 데이지호에 대한 제안입니다.</td>\n",
              "      <td>9</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>27</td>\n",
              "      <td>정치개혁</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-09-18</td>\n",
              "      <td>naver - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>김이수 헌재소장 임명 재고 건의</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문 대통령님께 묻습니다 (2017. 8....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>33</td>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>naver - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>납득할 수 있는 장애 재판정을 받고 싶습니다.</td>\n",
              "      <td>15</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t안녕하십니까? 저는 경직형 양마비 뇌병변...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>35</td>\n",
              "      <td>외교/통일/국방</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-08-26</td>\n",
              "      <td>kakao - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>문재인정부는 신한국형 페리프로세스가 작성했습니다.</td>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님 신한국형 페리프로세스 로...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>36</td>\n",
              "      <td>인권/성평등</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>2017-08-26</td>\n",
              "      <td>naver - ***</td>\n",
              "      <td>청원종료</td>\n",
              "      <td>한국채식인구 100만명. 학교 급식 및 군대에서 현미채식 선택권을 보장해주십시오!</td>\n",
              "      <td>1</td>\n",
              "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님과 각 정부 인사분들께 마...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    num  category  ... count                                  petition_overview\n",
              "0    21     안전/환경  ...     9  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...\n",
              "6    27      정치개혁  ...     1  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문 대통령님께 묻습니다 (2017. 8....\n",
              "12   33    인권/성평등  ...    15  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t안녕하십니까? 저는 경직형 양마비 뇌병변...\n",
              "14   35  외교/통일/국방  ...     0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님 신한국형 페리프로세스 로...\n",
              "15   36    인권/성평등  ...     1  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님과 각 정부 인사분들께 마...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4mqYZJFpWb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df['petition_overview']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7-iKoxcpWcA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g0khwexpWcH",
        "colab_type": "code",
        "outputId": "a79eec8a-f341-4a21-d06e-71dea8e48203",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "X[:10]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t스텔라 데이지호에 대한 제안입니다. \\n...\n",
              "6     \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문 대통령님께 묻습니다 (2017. 8....\n",
              "12    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t안녕하십니까? 저는 경직형 양마비 뇌병변...\n",
              "14    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님 신한국형 페리프로세스 로...\n",
              "15    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님과 각 정부 인사분들께 마...\n",
              "17    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t문재인 대통령님 한중관계 사드 갈등 해소...\n",
              "19    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t지금부터 67년전 1950년 6.25전쟁...\n",
              "25    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t지금부터 67년전 1950년 6.25전쟁...\n",
              "30    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t간절히 간절히 간청 드립니다. \\n\\n\\...\n",
              "54    \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t※지장물관련 국토부의 해석 : 기존 건축...\n",
              "Name: petition_overview, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwydAmFCpWcQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRHXGF47pWcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpoGwXuHpWcb",
        "colab_type": "code",
        "outputId": "a37191c5-8e2b-4e61-af94-cdcebc227d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "print(len(y_train))\n",
        "print(len(y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "129820\n",
            "32455\n",
            "129820\n",
            "32455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGdx9tJSpWcj",
        "colab_type": "code",
        "outputId": "3418c35c-bc4e-4636-d56d-610f73d3bc7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "print(X_train.head())\n",
        "print(y_train.head())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "333598    봄에 이어 이번 가을 겨울에도 어김없이 미세먼지가 왔습니다 적어도 봄에는 마스크 안...\n",
            "344228    부동산 계약 전산화 해야 합니다  부동산 계약 전산화 해야 합니다  부동산 계약 전...\n",
            "300621    어제 뉴스를 보고 너무 어이가 없어서 올려봅니다 동료들한테 처음 들었을 때 너무 황...\n",
            "285042    최근 국방의 의무에 관련하여 지속적으로 이야기가 나오고있습니다 국방의 의무에대하여 ...\n",
            "26544                                          조두순 재심 해주세요 \n",
            "Name: petition_overview, dtype: object\n",
            "333598       안전/환경\n",
            "344228    교통/건축/국토\n",
            "300621      인권/성평등\n",
            "285042    외교/통일/국방\n",
            "26544        안전/환경\n",
            "Name: category, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKHTsr9F0lSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bert_add(body):\n",
        "    lst = kss.split_sentences(body)\n",
        "    result = [\"SEP\"] * (len(lst) * 2 + 1)\n",
        "    result[1::2] = lst\n",
        "    result[0] = \"CLS\"\n",
        "    sentence = ' '.join(result)\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX11cyCn65rQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_dict = {'정치개혁': 0, '인권/성평등': 1, '안전/환경': 2, '교통/건축/국토': 3, '외교/통일/국방': 4}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La_E96eVyH2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_bert = []\n",
        "for body in X_train:\n",
        "    X_train_bert.append(bert_add(body))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPkZNltZ5sQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_bert = []\n",
        "for label in y_train:\n",
        "    y_train_bert.append(label_dict[label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuZCimqyOLay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "36a247b84adf4e958a6d55302a960f2c",
            "e4545e5b6dda4516ae0e3fd1115526a6",
            "99ac7cd00eeb40c0ac6b22c0eb0759bf",
            "76341434a51a4f8eab9969d18b421140",
            "1f5496314dc04115aa63267e2a18d0c8",
            "8bbf24a37a3a4487826e62659bdad18a",
            "02109d98293d48ad9f54e5f7c1b9238b",
            "a3da0556a16445c2a346981d9542c438"
          ]
        },
        "outputId": "7bfe2ea1-e69f-4fd5-b2d2-d0e8aa5dfa90"
      },
      "source": [
        "mecab = Mecab()\n",
        "tokenized_texts = []\n",
        "tokens_and_ids = {}\n",
        "\n",
        "for sent in tqdm_notebook(X_train_bert):\n",
        "  sent_morph = mecab.morphs(sent)\n",
        "  for i in range(len(sent_morph)):\n",
        "      if sent_morph[i] == 'CLS':\n",
        "          sent_morph[i] = '[CLS]'\n",
        "      elif sent_morph[i] == 'SEP':\n",
        "          sent_morph[i] = '[SEP]'\n",
        "      if sent_morph[i] not in tokens_and_ids.keys():\n",
        "          tokens_and_ids[sent_morph[i]] = len(tokens_and_ids.keys()) + 1\n",
        "\n",
        "  tokenized_texts.append(sent_morph)\n",
        "\n",
        "print (X_train_bert[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36a247b84adf4e958a6d55302a960f2c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=129820), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CLS 봄에 이어 이번 가을 겨울에도 어김없이 미세먼지가 왔습니다 SEP 적어도 봄에는 마스크 안써도 이정도까지는 아니였습니다 SEP 근데 지금 하늘이 뿌얗다못해 누렇습니다 SEP 게다가 마스크를 쓰는데도 불구하고 실내에 공기청정기를 켰는데도 불구하고 목이 계속 칼칼합니다 SEP 다음날 아침에는 목에 자꾸 가래가 생깁니다 SEP 미세먼지임에도 불구하고 누구는 목이 아픈게 환절기때문에 감기에 걸린것 같다고 합니다 SEP 또 밖이 뿌얗다보니 안개라고 오해하는 사람도 있었습니다 SEP 봄에는 미세먼지를 중국이 아닌 자동차 매연때문이라며 자가용 이용을 자제하고 대중교통을 이용하라고 교통비를 안받던적도 있었습니다 SEP 국민이 바보입니까 자동차 매연때문인지 중국에서 날라오는건지도 모를만큼요 지금 북한에 신경쓰고 계신건 알고 있습니다만 국민 먼저 살리는게 우선아닐까요 SEP 우리나라의 앞으로의 미래  먼 미래를 위해 앞으로 이나라에서 커갈 아이들을 위해 안전을 위해 그러시는건 알고있습니다 SEP 하지만 그 미래를 맞이하기도 전에 미세먼지 때문에 아플 아이들이 국민들이 있을 수 있습니다 SEP 건강해야 살아야 뭐든 좋게 맞이하지 않을까요 SEP 지금의 문제도 뒤돌아 봐주시길 바랍니다 SEP 미세먼지 해결 부탁드립니다 SEP\n",
            "['[CLS]', '봄', '에', '이어', '이번', '가을', '겨울', '에', '도', '어김없이', '미세먼지', '가', '왔', '습니다', '[SEP]', '적어도', '봄', '에', '는', '마스크', '안', '써도', '이', '정도', '까지', '는', '아니', '였', '습니다', '[SEP]', '근데', '지금', '하늘', '이', '뿌', '얗다못해', '누렇', '습니다', '[SEP]', '게다가', '마스크', '를', '쓰', '는', '데', '도', '불구', '하', '고', '실내', '에', '공기', '청정기', '를', '켰', '는데', '도', '불구', '하', '고', '목', '이', '계속', '칼칼', '합니다', '[SEP]', '다음', '날', '아침', '에', '는', '목', '에', '자꾸', '가래', '가', '생깁니다', '[SEP]', '미세먼지', '임', '에', '도', '불구', '하', '고', '누구', '는', '목', '이', '아픈게', '환절기', '때문', '에', '감기', '에', '걸린', '것', '같', '다고', '합니다', '[SEP]', '또', '밖', '이', '뿌', '얗다보니', '안개', '라고', '오해', '하', '는', '사람', '도', '있', '었', '습니다', '[SEP]', '봄', '에', '는', '미세먼지', '를', '중국', '이', '아닌', '자동차', '매연', '때문', '이', '라며', '자가용', '이용', '을', '자제', '하', '고', '대중교통', '을', '이용', '하', '라고', '교통비', '를', '안', '받', '던', '적', '도', '있', '었', '습니다', '[SEP]', '국민', '이', '바보', '입니까', '자동차', '매연', '때문', '인지', '중국', '에서', '날라오', '는', '건지', '도', '모를', '만큼', '요', '지금', '북한', '에', '신경', '쓰', '고', '계신', '건', '알', '고', '있', '습니다', '만', '국민', '먼저', '살리', '는', '게', '우선', '아닐까요', '[SEP]', '우리나라', '의', '앞', '으로', '의', '미래', '먼', '미래', '를', '위해', '앞', '으로', '이', '나라', '에서', '커갈', '아이', '들', '을', '위해', '안전', '을', '위해', '그러', '시', '는', '건', '알', '고', '있', '습니다', '[SEP]', '하지만', '그', '미래', '를', '맞이', '하', '기', '도', '전', '에', '미세먼지', '때문', '에', '아플', '아이', '들', '이', '국민', '들', '이', '있', '을', '수', '있', '습니다', '[SEP]', '건강', '해야', '살', '아야', '뭐', '든', '좋', '게', '맞이', '하', '지', '않', '을까요', '[SEP]', '지금', '의', '문제', '도', '뒤돌', '아', '봐', '주', '시', '길', '바랍니다', '[SEP]', '미세먼지', '해결', '부탁', '드립니다', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH_Np4NUVLcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = []\n",
        "for text in tokenized_texts:\n",
        "    morphs = []\n",
        "    for morph in text:\n",
        "        morphs.append(tokens_and_ids[morph])\n",
        "    input_ids.append(morphs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_hABlHe86fI",
        "colab_type": "code",
        "outputId": "9b1096fd-56f4-4d8c-9f24-137e27afcca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "MAX_LEN = 256\n",
        "#input_ids = [tokens_and_ids[x] for x in tokenized_texts]\n",
        "input_ids = []\n",
        "for text in tokenized_texts:\n",
        "    morphs = []\n",
        "    for morph in text:\n",
        "        morphs.append(tokens_and_ids[morph])\n",
        "    input_ids.append(morphs)\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids[0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1,   2,   3,   4,   5,   6,   7,   3,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,   2,   3,  16,  17,  18,  19,  20,  21,  22,  16,\n",
              "        23,  24,  13,  14,  25,  26,  27,  20,  28,  29,  30,  13,  14,\n",
              "        31,  17,  32,  33,  16,  34,   8,  35,  36,  37,  38,   3,  39,\n",
              "        40,  32,  41,  42,   8,  35,  36,  37,  43,  20,  44,  45,  46,\n",
              "        14,  47,  48,  49,   3,  16,  43,   3,  50,  51,  11,  52,  14,\n",
              "        10,  53,   3,   8,  35,  36,  37,  54,  16,  43,  20,  55,  56,\n",
              "        57,   3,  58,   3,  59,  60,  61,  62,  46,  14,  63,  64,  20,\n",
              "        28,  65,  66,  67,  68,  36,  16,  69,   8,  70,  71,  13,  14,\n",
              "         2,   3,  16,  10,  32,  72,  20,  73,  74,  75,  57,  20,  76,\n",
              "        77,  78,  79,  80,  36,  37,  81,  79,  78,  36,  67,  82,  32,\n",
              "        18,  83,  84,  85,   8,  70,  71,  13,  14,  86,  20,  87,  88,\n",
              "        74,  75,  57,  89,  72,  90,  91,  16,  92,   8,  93,  94,  95,\n",
              "        26,  96,   3,  97,  33,  37,  98,  99, 100,  37,  70,  13, 101,\n",
              "        86, 102, 103,  16, 104, 105, 106,  14, 107, 108, 109, 110, 108,\n",
              "       111, 112, 111,  32, 113, 109, 110,  20, 114,  90, 115, 116, 117,\n",
              "        79, 113, 118,  79, 113, 119, 120,  16,  99, 100,  37,  70,  13,\n",
              "        14, 121, 122, 111,  32, 123,  36, 124,   8, 125,   3,  10,  57,\n",
              "         3, 126, 116, 117,  20,  86, 117,  20,  70,  79, 127,  70,  13,\n",
              "        14, 128, 129, 130, 131, 132, 133, 134, 104])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx0D-TT19DOT",
        "colab_type": "code",
        "outputId": "ee69f7e8-a59e-4326-8ea7-80c6007ce1a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckB-H0dw9Luj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    y_train_bert, \n",
        "                                                                                    random_state=2018, \n",
        "                                                                                    test_size=0.1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3Fo6R7o9RIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=2018, \n",
        "                                                       test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lyfQsYn9VS7",
        "colab_type": "code",
        "outputId": "26e8d0f4-7773-42c2-8608-eaf5f6675d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([    1,  3086,  3265,  2630,   188,  2086,  1277,  2019,    79,   623,\n",
            "         1472,   203,    14,  1453,  3086,  3265,  2630,   188,  1184,   338,\n",
            "           22,   101,    83,    79,   127,    70,    16,  3493,   100,    37,\n",
            "           70,    13,    14,  1184,   338,    11,  2229,    32,   410,   453,\n",
            "          338,  2270,  1379,  3051,    14,    20,  1472,   188,  2086,  2031,\n",
            "          157,    16,  3882,  1396,   101,   134,   188,  1472,   203,    14,\n",
            "          125,   889,   116,   108,  2456,   184,  2757,  1201,   188,  1999,\n",
            "          184,  1548, 10094,   203,    14,    20,   867,   960,   101,   154,\n",
            "          202,   481,  1140,    20,    67,   603,    36,   378,   272,  6097,\n",
            "         6932,  2141,   240,   135,   136,    13,    14,   107,   739,  5066,\n",
            "         2272,   294,   195,   114,    90,  6097,  6932,   700,  1140,    79,\n",
            "        24680,    99,  1396,  3749,   370,    33,    16,   104,    23,   239,\n",
            "        24601,   246,   247,    20,   423,   188,  1997,     3,  6769,     3,\n",
            "         1185,   120,    42,   122,   207,   117,  2146,     8,  3525, 10566,\n",
            "           36,   239,   116,   117, 16276,     3, 15133,  1693, 10094,   110,\n",
            "          852,   369,   439,   308,  2268,     3,  1201,   130,   127,    70,\n",
            "          693, 33759,   184,   714,   108,  1816,    79, 19528,   321,   781,\n",
            "          404,     3,     8,   949, 33760,    14,   404,    79,  6102,   108,\n",
            "         1816,    79,  2004,   781,  2277,  1513,  2268,  2085,  2277,    20,\n",
            "         6775,   239,  2277,   110,  2229,  5311,  2475,     3,  2630,     8,\n",
            "        19605,   452,    90,  1201,    79,   130,   127,    70,   180,    14,\n",
            "          651,  3086,   281,  1905,   192,   202,  1068,   711,  3070,    79,\n",
            "           83,    16,   207,   117,    20,   603,    36,   120,   124,   298,\n",
            "        10540,  1190,    67,   262,   127,    70,   378,    13,    14,   121,\n",
            "         1396,    61,   188,    69,   117,   188,  3052,    22,   499, 15196,\n",
            "         2150,   203,    14,  6097,  6932,   184])\n",
            "tensor(3)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])\n",
            "tensor([    1, 18671,   616,   101,   108,  1336,    20,  3276,     3,     8,\n",
            "           35,    36,    37,   155,   612,   188,    69,    20,  1493,   580,\n",
            "          184,  1982,    32,  1898,    13,    14,   167,   138,    16, 18671,\n",
            "          616,    11,    73, 24078,  8385,   203,    14,   195,   913,   108,\n",
            "         4893,   184,   995,   257,   710,   188,   155,  4850,    14, 18671,\n",
            "          616,    11,     5,   914,   184,   855,    36,    37,  7626,    90,\n",
            "          394,   134,   188,   313,  1169,   142,   202,   134,   378,    13,\n",
            "           14,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjR-vcpd9XHe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwN-NYm86wWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_bert = []\n",
        "for body in X_test:\n",
        "    X_test_bert.append(bert_add(body))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fSjR8om62ji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_bert = []\n",
        "for label in y_test:\n",
        "    y_test_bert.append(label_dict[label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1iW-ZpmWQEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122,
          "referenced_widgets": [
            "c6b7cc3ca82e47b688628a77bcab8ea4",
            "99b07a1086c24bf8a4ab2dc9918cdec7",
            "ac77aaed79794544b2788a0dad5ff710",
            "32d80a28400d4beba36dd42942d0600d",
            "e7eb3b42704842988479885ad3c9766d",
            "6586c3f4ecf047aea61c946c2b4ce468",
            "2f74e475ac15479994bb9c1315181268",
            "02923463410c4a6eb21ae42dffae7df1"
          ]
        },
        "outputId": "4941b398-f203-424e-9e54-c99b67221846"
      },
      "source": [
        "mecab = Mecab()\n",
        "tokenized_texts = []\n",
        "\n",
        "for sent in tqdm_notebook(X_test_bert):\n",
        "  sent_morph = mecab.morphs(sent)\n",
        "  for i in range(len(sent_morph)):\n",
        "      if sent_morph[i] == 'CLS':\n",
        "          sent_morph[i] = '[CLS]'\n",
        "      elif sent_morph[i] == 'SEP':\n",
        "          sent_morph[i] = '[SEP]'\n",
        "      if sent_morph[i] not in tokens_and_ids.keys():\n",
        "          tokens_and_ids[sent_morph[i]] = len(tokens_and_ids.keys()) + 1\n",
        "\n",
        "  tokenized_texts.append(sent_morph)\n",
        "\n",
        "print (X_test_bert[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6b7cc3ca82e47b688628a77bcab8ea4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=32455), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CLS 주정차 위반한 차량을 구청소속 견인사무소에서 견인해갈때  왜 사전에 연락이 아예 없이 그대로 견인을 해가는지 저의가 궁금합니다 SEP 견인사무소에 가서 따져물어도 관련 근거 조례나 법령도 대지못하니 과태료및 견인비용을 수령하시는 분들은 욕한마디 먹지않고 수령하기는 거의 불가능하구요 SEP 연락을 하고 분정도뒤에 견인해가면  그나마 그분들이 욕도 안먹고 납부자들도 인정할수밖에없다고 생각합니다 SEP 아니면 정책을 만드시는 분들은 세금을 걷어야하고  세금을 수령하는 과정에서 수령기관자들이 욕먹는 것은 자신이 욕먹는게 아니니까 상관없다는 식으로 일임 하시는건가요 SEP 저의가 상당히 궁금합니다 SEP 왜 연락이나 통보 한마디 없이 견인해가는 속내가 뭡니까 SEP\n",
            "['[CLS]', '주정차', '위반', '한', '차량', '을', '구청', '소속', '견인', '사무소', '에서', '견인', '해', '갈', '때', '왜', '사전', '에', '연락', '이', '아예', '없이', '그대로', '견인', '을', '해', '가', '는지', '저의', '가', '궁금', '합니다', '[SEP]', '견인', '사무소', '에', '가', '서', '따져물', '어도', '관련', '근거', '조례', '나', '법령', '도', '대', '지', '못하', '니', '과태료', '및', '견인', '비용', '을', '수령', '하', '시', '는', '분', '들', '은', '욕', '한마디', '먹', '지', '않', '고', '수령', '하', '기', '는', '거의', '불', '가능', '하', '구요', '[SEP]', '연락', '을', '하', '고', '분', '정도', '뒤', '에', '견인', '해', '가', '면', '그나마', '그분', '들', '이', '욕', '도', '안', '먹', '고', '납부', '자', '들', '도', '인정', '할', '수', '밖에', '없', '다고', '생각', '합니다', '[SEP]', '아니', '면', '정책', '을', '만드', '시', '는', '분', '들', '은', '세금', '을', '걷', '어야', '하', '고', '세금', '을', '수령', '하', '는', '과정', '에서', '수령', '기관', '자', '들', '이', '욕먹', '는', '것', '은', '자신', '이', '욕먹', '는', '게', '아니', '니까', '상관없', '다는', '식', '으로', '일', '임', '하', '시', '는', '건가요', '[SEP]', '저의', '가', '상당히', '궁금', '합니다', '[SEP]', '왜', '연락', '이나', '통보', '한마디', '없이', '견인', '해', '가', '는', '속내', '가', '뭡니까', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hQoL5n090zo",
        "colab_type": "code",
        "outputId": "d839b90c-6d55-496c-bb35-850cf4126598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "MAX_LEN = 256\n",
        "\n",
        "#input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = []\n",
        "for text in tokenized_texts:\n",
        "    morphs = []\n",
        "    for morph in text:\n",
        "        morphs.append(tokens_and_ids[morph])\n",
        "    input_ids.append(morphs)\n",
        "    \n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    1,  7503,  1751,   195,  1176,    79,  1059,  5478, 12377,\n",
              "        6063,    90, 12377,   410,  1083,   164,   174,  2205,     3,\n",
              "        5936,    20,  3509,  1026,  2820, 12377,    79,   410,    11,\n",
              "        1481, 30681,    11,  3814,    46,    14, 12377,  6063,     3,\n",
              "          11,  1001, 49672,   255,   593,  1207,   306,   499,  3812,\n",
              "           8,   257,   135,   365,   920,  9014,   814, 12377,   923,\n",
              "          79,  5767,    36,   120,    16,   207,   117,   188,  1434,\n",
              "        3116,  2838,   135,   136,    37,  5767,    36,   124,    16,\n",
              "        2174,   770,   267,    36,  1052,    14,  5936,    79,    36,\n",
              "          37,   207,    21,  2105,     3, 12377,   410,    11,   202,\n",
              "        1266,  6030,   117,    20,  1434,     8,    18,  2838,    37,\n",
              "         775,   338,   117,     8,   680,   262,   127,  2990,   157,\n",
              "          62,   603,    46,    14,    23,   202,  1472,    79,  1855,\n",
              "         120,    16,   207,   117,   188,  2623,    79,  5342,   320,\n",
              "          36,    37,  2623,    79,  5767,    36,    16,  2406,    90,\n",
              "        5767,  1050,   338,   117,    20,  3578,    16,    60,   188,\n",
              "         328,    20,  3578,    16,   104,    23,   362, 12646,   237,\n",
              "         428,   110,   383,    53,    36,   120,    16,  1312,    14,\n",
              "       30681,    11,  2658,  3814,    46,    14,   174,  5936,   563,\n",
              "        2721,  3116,  1026, 12377,   410,    11,    16,  6983,    11,\n",
              "        6973,    14,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmwhcQQR95JN",
        "colab_type": "code",
        "outputId": "6299d466-87d9-490a-9019-29377fc7b575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcttgfyQ96hp",
        "colab_type": "code",
        "outputId": "8bbe3c5f-3f6b-43cc-c2f6-897cde145720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        }
      },
      "source": [
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(y_test_bert)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([    1,  7503,  1751,   195,  1176,    79,  1059,  5478, 12377,  6063,\n",
            "           90, 12377,   410,  1083,   164,   174,  2205,     3,  5936,    20,\n",
            "         3509,  1026,  2820, 12377,    79,   410,    11,  1481, 30681,    11,\n",
            "         3814,    46,    14, 12377,  6063,     3,    11,  1001, 49672,   255,\n",
            "          593,  1207,   306,   499,  3812,     8,   257,   135,   365,   920,\n",
            "         9014,   814, 12377,   923,    79,  5767,    36,   120,    16,   207,\n",
            "          117,   188,  1434,  3116,  2838,   135,   136,    37,  5767,    36,\n",
            "          124,    16,  2174,   770,   267,    36,  1052,    14,  5936,    79,\n",
            "           36,    37,   207,    21,  2105,     3, 12377,   410,    11,   202,\n",
            "         1266,  6030,   117,    20,  1434,     8,    18,  2838,    37,   775,\n",
            "          338,   117,     8,   680,   262,   127,  2990,   157,    62,   603,\n",
            "           46,    14,    23,   202,  1472,    79,  1855,   120,    16,   207,\n",
            "          117,   188,  2623,    79,  5342,   320,    36,    37,  2623,    79,\n",
            "         5767,    36,    16,  2406,    90,  5767,  1050,   338,   117,    20,\n",
            "         3578,    16,    60,   188,   328,    20,  3578,    16,   104,    23,\n",
            "          362, 12646,   237,   428,   110,   383,    53,    36,   120,    16,\n",
            "         1312,    14, 30681,    11,  2658,  3814,    46,    14,   174,  5936,\n",
            "          563,  2721,  3116,  1026, 12377,   410,    11,    16,  6983,    11,\n",
            "         6973,    14,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0])\n",
            "tensor(3)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-Wn4iSY-EkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxdURrvA-G0L",
        "colab_type": "code",
        "outputId": "11b0ee07-849a-441d-f184-e866845f1131",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5mElZBb-I70",
        "colab_type": "code",
        "outputId": "eb3042b7-e11e-48dc-efde-6e22a52764a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJztaLr2-KRW",
        "colab_type": "code",
        "outputId": "8019f0e1-23b0-47f4-9b5d-574e77c6cba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "761e88f83d704ed59ce068eeb81ea978",
            "89cb51f21d204630b8045a1efa5b0237",
            "10640f19e1e940e6b3a780b9ba8af291",
            "9dfe51ed93c14c9a92d7b88cc473223b",
            "a99cdcd63fbf42b2b43599763b866078",
            "bc345573f8b546ff8a6b0e9e15c4259f",
            "dc984c98797a49b1b729788551371934",
            "4c92eae3851944858df66ecac26754c6"
          ]
        }
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=5)\n",
        "model.cuda()\n",
        "#model.to(device)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "761e88f83d704ed59ce068eeb81ea978",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=714314041, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onhakyaA-Ly9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0hSAjgN-Qqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbhC_YdK-R6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m70Hyqvp-S9E",
        "colab_type": "code",
        "outputId": "46f51d20-9115-4e6c-b74a-10af76cf3799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  3,652.    Elapsed: 0:12:53.\n",
            "  Batch 1,000  of  3,652.    Elapsed: 0:25:53.\n",
            "  Batch 1,500  of  3,652.    Elapsed: 0:38:52.\n",
            "  Batch 2,000  of  3,652.    Elapsed: 0:51:51.\n",
            "  Batch 2,500  of  3,652.    Elapsed: 1:04:50.\n",
            "  Batch 3,000  of  3,652.    Elapsed: 1:17:49.\n",
            "  Batch 3,500  of  3,652.    Elapsed: 1:30:48.\n",
            "\n",
            "  Average training loss: 0.86\n",
            "  Training epcoh took: 1:34:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.73\n",
            "  Validation took: 0:03:32\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  3,652.    Elapsed: 0:12:59.\n",
            "  Batch 1,000  of  3,652.    Elapsed: 0:25:59.\n",
            "  Batch 1,500  of  3,652.    Elapsed: 0:38:58.\n",
            "  Batch 2,000  of  3,652.    Elapsed: 0:51:58.\n",
            "  Batch 2,500  of  3,652.    Elapsed: 1:04:57.\n",
            "  Batch 3,000  of  3,652.    Elapsed: 1:17:55.\n",
            "  Batch 3,500  of  3,652.    Elapsed: 1:30:54.\n",
            "\n",
            "  Average training loss: 0.64\n",
            "  Training epcoh took: 1:34:50\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:03:32\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  3,652.    Elapsed: 0:12:59.\n",
            "  Batch 1,000  of  3,652.    Elapsed: 0:25:57.\n",
            "  Batch 1,500  of  3,652.    Elapsed: 0:38:56.\n",
            "  Batch 2,000  of  3,652.    Elapsed: 0:51:55.\n",
            "  Batch 2,500  of  3,652.    Elapsed: 1:04:54.\n",
            "  Batch 3,000  of  3,652.    Elapsed: 1:17:53.\n",
            "  Batch 3,500  of  3,652.    Elapsed: 1:30:51.\n",
            "\n",
            "  Average training loss: 0.54\n",
            "  Training epcoh took: 1:34:47\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:03:32\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  3,652.    Elapsed: 0:12:59.\n",
            "  Batch 1,000  of  3,652.    Elapsed: 0:25:58.\n",
            "  Batch 1,500  of  3,652.    Elapsed: 0:38:57.\n",
            "  Batch 2,000  of  3,652.    Elapsed: 0:51:56.\n",
            "  Batch 2,500  of  3,652.    Elapsed: 1:04:55.\n",
            "  Batch 3,000  of  3,652.    Elapsed: 1:17:54.\n",
            "  Batch 3,500  of  3,652.    Elapsed: 1:30:53.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 1:34:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.75\n",
            "  Validation took: 0:03:32\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BtHiaum-Ui9",
        "colab_type": "code",
        "outputId": "07f355db-fca7-4d43-c558-314fc1dae943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,015.    Elapsed: 0:00:52.\n",
            "  Batch   200  of  1,015.    Elapsed: 0:01:45.\n",
            "  Batch   300  of  1,015.    Elapsed: 0:02:37.\n",
            "  Batch   400  of  1,015.    Elapsed: 0:03:29.\n",
            "  Batch   500  of  1,015.    Elapsed: 0:04:22.\n",
            "  Batch   600  of  1,015.    Elapsed: 0:05:14.\n",
            "  Batch   700  of  1,015.    Elapsed: 0:06:06.\n",
            "  Batch   800  of  1,015.    Elapsed: 0:06:59.\n",
            "  Batch   900  of  1,015.    Elapsed: 0:07:51.\n",
            "  Batch 1,000  of  1,015.    Elapsed: 0:08:43.\n",
            "\n",
            "Accuracy: 0.75\n",
            "Test took: 0:08:51\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}